{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "!pip install natsort\n!pip install tensorflow_datasets"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#imports\nfrom zipfile import ZipFile\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\nimport io\nimport numpy as np\nimport random\nimport cv2\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom pathlib import Path\nfrom natsort import natsorted\nimport sklearn\n\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\n\nfrom sklearn.model_selection import train_test_split\n\n#from preprocessing import Preprocessing"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "device_name = tf.test.gpu_device_name()\nif device_name != '/device:GPU:0':\n  raise SystemError('GPU device not found')\nprint('Found GPU at: {}'.format(device_name))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# auxiliary function that you are already familiar with\nimport zipfile\ndef get_zip(file_name):\n    '''\n    file_name = Name of zip file you want to download from object storage\n    '''\n    try:\n        fobj = open(file_name, \"wb\")\n        fobj.write(project.get_file(file_name).read()) \n        fobj.close()\n        z = zipfile.ZipFile(file_name)\n        z.extractall()\n    except Exception as e:\n        print(Exception,e)\n    else:\n        print('Files downloaded successfully')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "get_zip('preprocessed.zip')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "metadata_csv = cos_client.get_object(Bucket=bucket, Key='cancer_metadata.csv')['Body']\nmetadata = pd.read_csv(metadata_csv)\nmetadata.columns"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "benign_count = len(metadata[ metadata['benign_malignant'] == 'benign'])\nmalignant_count = len(metadata[ metadata['benign_malignant'] == 'malignant'])\nmalignant_frac = malignant_count / (benign_count + malignant_count) * 100\n\nprint(benign_count)\nprint(malignant_count)\nprint(malignant_frac)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#stratified sampling\nmetadata = metadata.iloc[range(int(len(metadata)* 0.5))]\nf = 0.35\ntrain_df, test_df = train_test_split(metadata, test_size=f)\ntrain_df, val_df = train_test_split(train_df, test_size=f)\n\n# train_df = metadata.groupby('benign_malignant', group_keys=False).apply(lambda x: x.sample(frac=f))\n\nbenign_count = len(train_df[ train_df['benign_malignant'] == 'benign'])\nmalignant_count = len(train_df[ train_df['benign_malignant'] == 'malignant'])\nmalignant_frac = malignant_count / (benign_count + malignant_count) * 100\n\nprint(f\"Benign: {benign_count}\")\nprint(f\"Malignant: {malignant_count}\")\nprint(f\"Malignant fraction: {malignant_frac:.2f}%\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "benign_count = len(val_df[ val_df['benign_malignant'] == 'benign'])\nmalignant_count = len(val_df[ val_df['benign_malignant'] == 'malignant'])\nmalignant_frac = malignant_count / (benign_count + malignant_count) * 100\n\nprint(f\"Benign: {benign_count}\")\nprint(f\"Malignant: {malignant_count}\")\nprint(f\"Malignant fraction: {malignant_frac:.2f}%\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "benign_count = len(test_df[ test_df['benign_malignant'] == 'benign'])\nmalignant_count = len(test_df[ test_df['benign_malignant'] == 'malignant'])\nmalignant_frac = malignant_count / (benign_count + malignant_count) * 100\n\nprint(f\"Benign: {benign_count}\")\nprint(f\"Malignant: {malignant_count}\")\nprint(f\"Malignant fraction: {malignant_frac:.2f}%\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "train_df"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "pos_features = train_df[ train_df['benign_malignant'] == 'malignant'].reset_index()\nneg_features = train_df[ train_df['benign_malignant'] == 'benign'].reset_index()\n\nids = np.arange(len(pos_features))\nchoices = np.random.choice(ids, len(neg_features))\n\nres_pos_features = pos_features.iloc[choices]\nres_df = pd.concat([res_pos_features, neg_features])\n\nneg = len(neg_features)\nprint(neg_features.shape)\nprint(pos_features.shape)\nprint(res_pos_features.shape)\nprint(res_df.shape)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import shutil\nimport os\n\ndef local_filename(row):\n    return row['isic_id'] + \".JPG\"\n\ndef download_df(df, folder=\"cancer\"):\n\n    def save_image(img_name, path_prefix):\n        src_filepath = os.path.join(source_folder, img_name)\n        dest_filepath = os.path.join(path_prefix, img_name)\n        shutil.copyfile(src_filepath, dest_filepath)\n\n    benin = df[df['benign_malignant'] == 'benign']\n    malignat = df[df['benign_malignant'] == 'malignant']\n\n    benin_filenames = benin.apply(local_filename, axis=1)\n    malignat_filenames = malignat.apply(local_filename, axis=1)\n\n    p = os.path.join(folder, \"\")\n    os.makedirs(p, exist_ok=True)\n    benin_path = os.path.join(p, 'benign')\n    os.makedirs(benin_path, exist_ok=True)\n    malignat_path = os.path.join(p, 'malignant')\n    os.makedirs(malignat_path, exist_ok=True)\n\n    source_folder = \"preprocessed\"  # Specify the path to your local folder here\n\n    for img_name in benin_filenames:\n        save_image(img_name, benin_path)\n\n    for img_name in malignat_filenames:\n        save_image(img_name, malignat_path)\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "download_df(train_df, \"cancer/train\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "download_df(val_df, \"cancer/val\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "download_df(test_df, \"cancer/test\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def copy_resampled_images(resampled_df, path):\n    pos_features =  resampled_df[ resampled_df['benign_malignant'] == 'malignant']\n    img_names = pos_features.apply(bucket_filename, axis=1)\n    \n    p = Path(path)\n    \n    for (img_name, count) in img_names.groupby(img_names).count().items():\n        orig_img = p / img_name\n        for i in range(count-1):\n            copied_name = str(orig_img) + \"_\" + str(i)\n            !cp {orig_img} {copied_name}"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "img_height, img_width = 100, 100\nbatch_size = 32\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    \"cancer/train\",\n    image_size=(img_height, img_width),\n    batch_size=batch_size,\n    label_mode='binary')\n\nval_ds = tf.keras.utils.image_dataset_from_directory(\n    \"cancer/val\",\n    image_size=(img_height, img_width),\n    batch_size=batch_size,\n    label_mode='binary')\n\ntest_ds = tf.keras.utils.image_dataset_from_directory(\n    \"cancer/test\",\n    image_size=(img_height, img_width),\n    batch_size=batch_size,\n    label_mode='binary')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "class_names = train_ds.class_names\n#print(class_names)\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[int(labels[i] > 0.5)])\n    plt.axis(\"off\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from xgboost import XGBClassifier\n\ntrain_ds = train_ds.unbatch()\nX_train = np.array(list(train_ds.map(lambda x, y: x)))\ny_train = np.array(list(train_ds.map(lambda x, y: y)))\n\n# Reshape the input data\nnum_samples, height, width, channels = X_train.shape\nX_train = X_train.reshape(num_samples, height * width * channels)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "val_ds = val_ds.unbatch()\nX_val = np.array(list(val_ds.map(lambda x, y: x)))\ny_val = np.array(list(val_ds.map(lambda x, y: y)))\n\nnum_samples, height, width, channels = X_val.shape\nX_val = X_val.reshape(num_samples, height * width * channels)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "test_ds = test_ds.unbatch()\nX_test = np.array(list(test_ds.map(lambda x, y: x)))\ny_test= np.array(list(test_ds.map(lambda x, y: y)))\n\nnum_samples, height, width, channels = X_test.shape\nX_test = X_test.reshape(num_samples, height * width * channels)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "neg = len(metadata[metadata['benign_malignant'] == 'benign'])\npos = len(metadata[metadata['benign_malignant'] == 'malignant'])\ntotal = neg + pos\ninitial_bias = np.log([pos / neg])\n\nweight_for_0 = (1 / neg) * (total / 2.0)\nweight_for_1 = (1 / pos) * (total / 2.0)\n\nprint(f\"weight for 0: {weight_for_0}\")\nprint(f\"weight for 1: {weight_for_1}\")\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def report_best_scores(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'])\n        for candidate in candidates:\n            print('Model with rank: {0}'.format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n                results['mean_test_score'][candidate], \n                results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "xgb_model = XGBClassifier(scale_pos_weight=class_weight[1], n_iter = 100, random_state = 42)\n\nparams = {\n    \"gamma\": [i/100 for i in range(0, 51, 10)],\n    \"learning_rate\": [i/100 for i in range(1, 26, 6)],\n    \"max_depth\": range(2, 10, 2),\n    \"reg_alpha\": range(1, 100, 25),\n}"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, RandomizedSearchCV\n\ngrid_search = GridSearchCV(\n                            estimator = xgb_model,\n                            param_grid=params,\n                            scoring='roc_auc',\n                            n_jobs = 1,\n                            cv = 3,\n                            verbose=True)\ngrid_search.fit(X_train, y_train)\nreport_best_scores(search.cv_results_, 3)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#y_pred = XGB.predict(X_test)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#from sklearn import metrics\n#print(f\"f1 = {metrics.f1_score(y_test, y_pred)}\")\n#print(f\"precision = {metrics.precision_score(y_test, y_pred)}\")\n#print(f\"recall = {metrics.recall_score(y_test, y_pred)}\")\n#print(f\"accuracy = {metrics.accuracy_score(y_test, y_pred)}\")\n#print(f\"MCC = {metrics.matthews_corrcoef(y_test, y_pred)}\")\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#import pickle\n\n#filename = 'xgb_model_smaller_19_06.pkl'\n#pickle.dump(XGB, open(filename, 'wb'))\n\n# Later, you can load the saved model using:\n#loaded_model = pickle.load(open(filename, 'rb'))\n"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10 + GPU",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}